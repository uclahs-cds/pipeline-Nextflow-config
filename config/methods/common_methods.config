import nextflow.util.SysHelper
includeConfig "../schema/schema.config"

/**
*   This methods namespace contains common functions for pipeline set up.
*/
methods {
    /**
    *   Detect and load base and node-specific resource allocations
    */
    set_resources_allocation = {
        def node_cpus = SysHelper.getAvailCpus()
        def node_memory_GB = SysHelper.getAvailMemory().toGiga()
        // Load base.config by default for all pipelines
        includeConfig "${projectDir}/config/base.config"
        def config_to_include = ""
        if (params.containsKey('ucla_cds') && params.ucla_cds) {
            if (node_cpus == 64) {
                // Check memory for M64 node
                if (node_memory_GB >= 950 && node_memory_GB <= 1010) {
                    config_to_include = "${projectDir}/config/M64.config"
                } else {
                    throw new Exception("     ### ERROR ###     System resources not as expected (cpus=${node_cpus} memory=${node_memory_GB}), unable to assign resources.")
                }
            } else {
                // Check memory for F series node
                if (node_memory_GB >= (node_cpus * 2 * 0.9 - 1) && node_memory_GB <= (node_cpus * 2)) {
                    config_to_include = "${projectDir}/config/F${node_cpus}.config"
                } else {
                    throw new Exception("     ### ERROR ###     System resources not as expected (cpus=${node_cpus} memory=${node_memory_GB}), unable to assign resources.")
                }
            }
            try {
                includeConfig config_to_include
            } catch(java.nio.file.NoSuchFileException file_not_found_exception) {
                System.out.println("     ### ERROR ###     The partition-specific config file: ${config_to_include} does not exist. The pipeline does not support the requested partition type.")
                throw file_not_found_exception
            }

        }
    }

    /**
    *   Extract the reference genome version from UCLA CDS path
    */
    get_genome_version = { Object genome_path ->
        def genome_real_path = ""
        try {
            // Resolve path to absolute path
            genome_real_path = new File(genome_path).toPath().toRealPath()
        } catch (Exception e) {
            throw new Exception("     ### ERROR ###     Failed to resolve genome path: ${genome_path}")
        }
        def pattern = ~/^\/hot\/ref\/reference\/(?<genomeversion>[A-Za-z0-9-]+)\/.+$/
        def matcher = genome_real_path =~ pattern
        matcher.matches()
        try {
            return matcher.group("genomeversion")
        } catch (Exception e) {
            throw new Exception("     ### ERROR ###     Failed to extract genome version: ${genome_real_path}. Expected path to follow UCLA CDS reference format: /hot/ref/reference/<genome_version>/...")
        }
    }

    /**
    *   Ensure all required params are provided
    */
    check_registered_output_params = {
        // TO-DO: Regex/custom validation for standardized fields, like dataset_id
        //          Can create a custom schema for dataset registration-specific fields
        def required_information = [
            'dataset_id',
            'patient_id',
            'sample_id',
            'ucla_cds_analyte',
            'ucla_cds_technology',
            'ucla_cds_reference_genome_version',
        ]

        def missing_information = []

        for (field in required_information) {
            if ( !(params.containsKey(field) && params[field])) {
                missing_information.add(field)
            }
        }

        if (missing_information.size != 0) {
            throw new Exception("     ### ERROR ###     Missing params required for registered dataset output directory generation: ${missing_information}.")
        }

        if (params.containsKey('save_intermediate_files') && params.save_intermediate_files) {
            params.save_intermediate_files = false
            System.out.println("      ### WARNING ###     Intermediate file saving has been automatically disabled with registered output.")
        }

    }

    /**
    *   Generate a UUID
    */
    generate_uuid = {
        return UUID.randomUUID().toString()
    }

    /**
    *   Generate the output path for registered output
    */
    generate_registered_output_directory = { Object data_dir="/hot/data" ->
        def STRING_TYPES = [String, GString]
        if (!STRING_TYPES.any{ data_dir in it }) {
            throw new Exception("     ### ERROR ###     Input data_dir for generate_registered_output_directory must be a String or GString!")
        }
        methods.check_registered_output_params()

        def disease = params.dataset_id.substring(0, 4)
        def registered_output_directory = "${data_dir}/${disease}/${params.dataset_id}/${params.patient_id}/${params.sample_id}/${params.ucla_cds_analyte}/${params.ucla_cds_technology}/aligned/${params.ucla_cds_reference_genome_version}"

        schema.check_path(registered_output_directory, 'w')
        return registered_output_directory
    }

    /**
    *   Parse the common publish dir rules
    */
    get_common_publish_dir_rules = {
        def common_publish_dir_rules = []
        if (process.publishDir) {
            if (process.publishDir in Map) {
                common_publish_dir_rules = [process.publishDir]
            } else if (process.publishDir in List) {
                common_publish_dir_rules = process.publishDir
            } else {
                throw new Exception("Unexpected common publishDir type: ${process.publishDir.getClass()}. Please define either a Map or a List of Maps")
            }
        }
        return common_publish_dir_rules
    }

    /**
    *   Set up specific process publishDir
    */
    get_publish_dir = {  Object aprocess, List common_publish_dir_rules, Boolean disable_common_rules ->
        def publish_dir_rules = []
        if (!disable_common_rules) {
            publish_dir_rules = common_publish_dir_rules
        }
        if (process[aprocess.key].publishDir) {
            if (process[aprocess.key].publishDir in Map) {
                publish_dir_rules = [process[aprocess.key].publishDir] + publish_dir_rules
            } else if (process[aprocess.key].publishDir in List) {
                publish_dir_rules = process[aprocess.key].publishDir + publish_dir_rules
            }
        }
        return publish_dir_rules
    }

    /**
    *   Combine the common publishDir rules with process-specific ones
    */
    merge_publish_dirs = {
        def common_publish_dir_rules = methods.get_common_publish_dir_rules()
        def disable_common_rules = false
        for (i in process) {
            if (i.key.startsWith('withName:')) {
                if (process[i.key].containsKey('disable_common_rules')) {
                    disable_common_rules = process[i.key].disable_common_rules
                    process[i.key].remove('disable_common_rules')
                } else {
                    disable_common_rules = false
                }
                process[i.key].publishDir = methods.get_publish_dir(i, common_publish_dir_rules, disable_common_rules)
            }
        }
    }
}
